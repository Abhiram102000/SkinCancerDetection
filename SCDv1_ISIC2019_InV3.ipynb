{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiram102000/SkinCancerDetection/blob/main/SCDv1_ISIC2019_InV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BXC8ItlFTDi9"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from os import listdir\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import get_file\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, \n",
        "from imblearn.metrics import sensitivity_score, specificity_score\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from PIL import Image\n",
        "import itertools\n",
        "\n",
        "# to get consistent results after multiple runs\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knsuq0n2N9sI"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "train_path = \"data_2019/train/\"\n",
        "test_path = \"data_2019/test/\"\n",
        "valid_path = \"data_2019/valid/\"\n",
        "\n",
        "os.makedirs(train_path + \"benign/\")\n",
        "os.makedirs(train_path + \"malignant/\")\n",
        "os.makedirs(test_path + \"benign/\")\n",
        "os.makedirs(test_path + \"malignant/\")\n",
        "os.makedirs(valid_path + \"benign/\")\n",
        "os.makedirs(valid_path + \"malignant/\")\n",
        "\n",
        "test_samples = train_samples = valid_samples =  0\n",
        "\n",
        "for line in open(\"data_2019/ISIC_2019_Training_GroundTruth.csv\").readlines()[1:]:\n",
        "  split_line = line.split(\",\")\n",
        "  img_name = split_line[0]\n",
        "  benign_malignant = split_line[1]\n",
        "  \n",
        "  r = random.random()\n",
        "\n",
        "  if r < 0.6:\n",
        "    loc = train_path\n",
        "    train_samples += 1\n",
        "  \n",
        "  elif r < 0.75:\n",
        "    loc = valid_path\n",
        "    valid_samples += 1\n",
        "\n",
        "  else:\n",
        "    loc = test_path\n",
        "    test_samples += 1\n",
        "\n",
        "\n",
        "  if int(float(benign_malignant)) == 0:\n",
        "    shutil.move(\"data_2019/ISIC_2019_Training_Input/\" + img_name + \".jpg\", loc + \"benign/\" + img_name + \".jpg\")\n",
        "  elif int(float(benign_malignant)) == 1:\n",
        "    shutil.move(\"data_2019/ISIC_2019_Training_Input/\" + img_name + \".jpg\", loc + \"malignant/\" + img_name + \".jpg\")\n",
        "  \n",
        "print(f\"Number of training examples {train_samples}\")\n",
        "print(f\"Number of test examples {test_samples}\")\n",
        "print(f\"Number of valid examples {valid_samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxuEE7gIaA2W"
      },
      "outputs": [],
      "source": [
        "def generate_csv(folder, label2int):\n",
        "    folder_name = os.path.basename(folder)\n",
        "    labels = list(label2int)\n",
        "    # generate CSV file\n",
        "    df = pd.DataFrame(columns=[\"filepath\", \"label\"])\n",
        "    i = 0\n",
        "    for label in labels:\n",
        "        print(\"Reading\", os.path.join(folder, label, \"*\"))\n",
        "        for filepath in glob.glob(os.path.join(folder, label, \"*\")):\n",
        "            df.loc[i] = [filepath, label2int[label]]\n",
        "            i += 1\n",
        "    output_file = f\"{folder_name}.csv\"\n",
        "    print(\"Saving\", output_file)\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "generate_csv(\"data_2019/train\", {\"benign\": 0, \"malignant\": 1})\n",
        "generate_csv(\"data_2019/valid\", {\"benign\": 0, \"malignant\": 1})\n",
        "generate_csv(\"data_2019/test\", {\"benign\": 0, \"malignant\": 1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzkmcXR6_1d3"
      },
      "outputs": [],
      "source": [
        "class_names = [\"benign\", \"malignant\"]\n",
        "\n",
        "train_metadata_filename = \"train.csv\"\n",
        "valid_metadata_filename = \"valid.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_metadata_filename)\n",
        "df_valid = pd.read_csv(valid_metadata_filename)\n",
        "n_training_samples = len(df_train)\n",
        "n_validation_samples = len(df_valid)\n",
        "\n",
        "print(\"Number of training samples:\", n_training_samples)\n",
        "print(\"Number of validation samples:\", n_validation_samples)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train[\"filepath\"], df_train[\"label\"]))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((df_valid[\"filepath\"], df_valid[\"label\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI7NGtkzd4pK"
      },
      "outputs": [],
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [299, 299])\n",
        "\n",
        "\n",
        "def process_path(filepath, label):\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(filepath)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "valid_ds = valid_ds.map(process_path)\n",
        "train_ds = train_ds.map(process_path)\n",
        "# test_ds = test_ds\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image shape:\", image.shape)\n",
        "    print(\"Label:\", label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGmeG0XaeBif"
      },
      "outputs": [],
      "source": [
        "batch_size = 55\n",
        "optimizer = \"rmsprop\"\n",
        "\n",
        "def prepare_for_training(ds, cache=True, batch_size=64, shuffle_buffer_size=1000):\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "  # shuffle the dataset\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "  # split to batches\n",
        "  ds = ds.batch(batch_size)\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "valid_ds = prepare_for_training(valid_ds, batch_size=batch_size, cache=\"valid-cached-data\")\n",
        "train_ds = prepare_for_training(train_ds, batch_size=batch_size, cache=\"train-cached-data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw4UzOxnl9s4"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(valid_ds))\n",
        "\n",
        "def show_batch(batch):\n",
        "  plt.figure(figsize=(12,12))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(batch[0][n])\n",
        "      plt.title(class_names[batch[1][n].numpy()].title())\n",
        "      plt.axis('off')\n",
        "        \n",
        "show_batch(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQPjdcDPt0H9"
      },
      "outputs": [],
      "source": [
        "module_url = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "m = tf.keras.Sequential([\n",
        "    hub.KerasLayer(module_url, output_shape=[2048], trainable=False),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "m.build([None, 299, 299, 3])\n",
        "m.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "m.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KsmSclCnULa"
      },
      "outputs": [],
      "source": [
        "model_name = f\"benign-vs-malignant_{batch_size}_{optimizer}\"\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "# saves model checkpoint whenever we reach better weights\n",
        "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(model_name + \"_{val_loss:.3f}.h5\", save_best_only=True, verbose=1)\n",
        "\n",
        "history = m.fit(train_ds, validation_data=valid_ds, \n",
        "                steps_per_epoch=n_training_samples // batch_size, \n",
        "                validation_steps=n_validation_samples // batch_size, verbose=1, epochs=10,\n",
        "                callbacks=[tensorboard, modelcheckpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GET75UR0nXqs"
      },
      "outputs": [],
      "source": [
        "test_metadata_filename = \"test.csv\"\n",
        "df_test = pd.read_csv(test_metadata_filename)\n",
        "n_testing_samples = len(df_test)\n",
        "print(\"Number of testing samples:\", n_testing_samples)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((df_test[\"filepath\"], df_test[\"label\"]))\n",
        "\n",
        "def prepare_for_testing(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  \n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  return ds\n",
        "\n",
        "\n",
        "test_ds = test_ds.map(process_path)\n",
        "test_ds = prepare_for_testing(test_ds, cache=\"test-cached-data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9oeoghpnfWB"
      },
      "outputs": [],
      "source": [
        "y_test = np.zeros((n_testing_samples,))\n",
        "X_test = np.zeros((n_testing_samples, 299, 299, 3))\n",
        "for i, (img, label) in enumerate(test_ds.take(n_testing_samples)):\n",
        "  # print(img.shape, label.shape)\n",
        "  X_test[i] = img\n",
        "  y_test[i] = label.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHwlwp1Gq-kK"
      },
      "outputs": [],
      "source": [
        "m.load_weights(\"benign-vs-malignant_55_rmsprop_1.514.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlz-sBiVrbR7"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating the model...\")\n",
        "loss, accuracy = m.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", loss, \"  Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xzj2a6gv4z3"
      },
      "outputs": [],
      "source": [
        "def get_predictions(threshold=None):\n",
        "  \"\"\"\n",
        "  Returns predictions for binary classification given `threshold`\n",
        "  For instance, if threshold is 0.3, then it'll output 1 (malignant) for that sample if\n",
        "  the probability of 1 is 30% or more (instead of 50%)\n",
        "  \"\"\"\n",
        "  y_pred = m.predict(X_test)\n",
        "  if not threshold:\n",
        "    threshold = 0.5\n",
        "  result = np.zeros((n_testing_samples,))\n",
        "  for i in range(n_testing_samples):\n",
        "    # test melanoma probability\n",
        "    if y_pred[i][0] >= threshold:\n",
        "      result[i] = 1\n",
        "    # else, it's 0 (benign)\n",
        "  return result\n",
        "\n",
        "threshold = 0.83\n",
        "\n",
        "y_pred = get_predictions(threshold)\n",
        "accuracy_after = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy after setting the threshold:\", accuracy_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rMmQwpo-axa"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "  cmn = confusion_matrix(y_test, y_pred)\n",
        "  # Normalise\n",
        "  cmn = cmn.astype('float') / cmn.sum(axis=1)[:, np.newaxis]\n",
        "  # print it\n",
        "  print(cmn)\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "  sns.heatmap(cmn, annot=True, fmt='.2f', \n",
        "              xticklabels=[f\"pred_{c}\" for c in class_names], \n",
        "              yticklabels=[f\"true_{c}\" for c in class_names],\n",
        "              cmap=\"Blues\"\n",
        "              )\n",
        "  plt.ylabel('Actual')\n",
        "  plt.xlabel('Predicted')\n",
        "  # plot the resulting confusion matrix\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_auc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    This function plots the ROC curves and provides the scores.\n",
        "    \"\"\"\n",
        "    # prepare for figure\n",
        "    plt.figure()\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "    # obtain ROC AUC\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    # print score\n",
        "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "    # plot ROC curve\n",
        "    plt.plot(fpr, tpr, color=\"blue\", lw=2,\n",
        "                label='ROC curve (area = {f:.2f})'.format(d=1, f=roc_auc))\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC curves')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "plot_roc_auc(y_test, y_pred)\n",
        "sensitivity = sensitivity_score(y_test, y_pred)\n",
        "specificity = specificity_score(y_test, y_pred)\n",
        "\n",
        "print(\"Melanoma Sensitivity:\", sensitivity)\n",
        "print(\"Melanoma Specificity:\", specificity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgEiTm_a_SyB"
      },
      "outputs": [],
      "source": [
        "def plot_images(X_test, y_pred, y_test):\n",
        "  predicted_class_names = np.array([class_names[int(round(id))] for id in y_pred])\n",
        "  \n",
        "  plt.figure(figsize=(10,9))\n",
        "  for n in range(30, 60):\n",
        "      plt.subplot(6,5,n-30+1)\n",
        "      plt.subplots_adjust(hspace = 0.3)\n",
        "      plt.imshow(X_test[n])\n",
        "      # get the predicted label\n",
        "      predicted_label = predicted_class_names[n]\n",
        "      # get the actual true label\n",
        "      true_label = class_names[int(round(y_test[n]))]\n",
        "      if predicted_label == true_label:\n",
        "          color = \"blue\"\n",
        "          title = predicted_label.title()\n",
        "      else:\n",
        "          color = \"red\"\n",
        "          title = f\"{predicted_label.title()}, true:{true_label.title()}\"\n",
        "      plt.title(title, color=color)\n",
        "      plt.axis('off')\n",
        "  _ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")\n",
        "  plt.show()\n",
        "\n",
        "plot_images(X_test, y_pred, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx0cT4b9CbZF"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kasvSsaJDIVn"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SCDv1_ISIC2019-InV3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9lA+GvwO3GmcBGkIoBW4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}