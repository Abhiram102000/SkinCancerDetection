{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCDv1_ISIC2019_ENB7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXmrNCvs4Wjp/shjL323zu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiram102000/SkinCancerDetection/blob/main/SCDv1_ISIC2019_ENB7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SNb0W7jcCZt"
      },
      "source": [
        "# Importing the libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.utils import get_file\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "from imblearn.metrics import sensitivity_score, specificity_score\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# to get consistent results after multiple runs\n",
        "tf.random.set_seed(10)\n",
        "np.random.seed(10)\n",
        "random.seed(10)\n",
        "\n",
        "# 0 for benign, 1 for malignant\n",
        "class_names = [\"benign\", \"malignant\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpkh2C3JcUaS"
      },
      "source": [
        "def download_and_extract_dataset():\n",
        "  # dataset from ISIC 2019 Challenge Data\n",
        "  train_url = \"https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip\"\n",
        "\n",
        "  for i, download_link in enumerate([train_url]):\n",
        "    temp_file = f\"temp{i}.zip\"\n",
        "    data_dir = get_file(origin=download_link, fname=os.path.join(os.getcwd(), temp_file))\n",
        "    print(\"Extracting\", download_link)\n",
        "    with zipfile.ZipFile(data_dir, \"r\") as z:\n",
        "      z.extractall(\"data\")\n",
        "    # remove the temp file\n",
        "    os.remove(temp_file)\n",
        "\n",
        "# comment the below line if you already downloaded the dataset\n",
        "download_and_extract_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knsuq0n2N9sI"
      },
      "source": [
        "import shutil\n",
        "\n",
        "train_path = \"data/train/\"\n",
        "test_path = \"data/test/\"\n",
        "valid_path = \"data/valid/\"\n",
        "\n",
        "#os.makedirs(train_path + \"benign/\")\n",
        "#os.makedirs(train_path + \"malignant/\")\n",
        "#os.makedirs(test_path + \"benign/\")\n",
        "#os.makedirs(test_path + \"malignant/\")\n",
        "#os.makedirs(valid_path + \"benign/\")\n",
        "#os.makedirs(valid_path + \"malignant/\")\n",
        "\n",
        "test_samples = train_samples = valid_samples =  0\n",
        "\n",
        "for line in open(\"data/ISIC_2019_Training_GroundTruth.csv\").readlines()[1:]:\n",
        "  split_line = line.split(\",\")\n",
        "  img_name = split_line[0]\n",
        "  benign_malignant = split_line[1]\n",
        "  \n",
        "  r = random.random()\n",
        "\n",
        "  if r < 0.6:\n",
        "    loc = train_path\n",
        "    train_samples += 1\n",
        "  \n",
        "  elif r < 0.75:\n",
        "    loc = valid_path\n",
        "    valid_samples += 1\n",
        "\n",
        "  else:\n",
        "    loc = test_path\n",
        "    test_samples += 1\n",
        "\n",
        "\n",
        "  if int(float(benign_malignant)) == 0:\n",
        "    shutil.move(\"data/ISIC_2019_Training_Input/\" + img_name + \".jpg\", loc + \"benign/\" + img_name + \".jpg\")\n",
        "  elif int(float(benign_malignant)) == 1:\n",
        "    shutil.move(\"data/ISIC_2019_Training_Input/\" + img_name + \".jpg\", loc + \"malignant/\" + img_name + \".jpg\")\n",
        "  \n",
        "print(f\"Number of training examples {train_samples}\")\n",
        "print(f\"Number of test examples {test_samples}\")\n",
        "print(f\"Number of valid examples {valid_samples}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxuEE7gIaA2W"
      },
      "source": [
        "def generate_csv(folder, label2int):\n",
        "    folder_name = os.path.basename(folder)\n",
        "    labels = list(label2int)\n",
        "    # generate CSV file\n",
        "    df = pd.DataFrame(columns=[\"filepath\", \"label\"])\n",
        "    i = 0\n",
        "    for label in labels:\n",
        "        print(\"Reading\", os.path.join(folder, label, \"*\"))\n",
        "        for filepath in glob.glob(os.path.join(folder, label, \"*\")):\n",
        "            df.loc[i] = [filepath, label2int[label]]\n",
        "            i += 1\n",
        "    output_file = f\"{folder_name}.csv\"\n",
        "    print(\"Saving\", output_file)\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "generate_csv(\"data/train\", {\"benign\": 0, \"malignant\": 1})\n",
        "generate_csv(\"data/valid\", {\"benign\": 0, \"malignant\": 1})\n",
        "generate_csv(\"data/test\", {\"benign\": 0, \"malignant\": 1})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzkmcXR6_1d3"
      },
      "source": [
        "train_metadata_filename = \"train.csv\"\n",
        "valid_metadata_filename = \"valid.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_metadata_filename)\n",
        "df_valid = pd.read_csv(valid_metadata_filename)\n",
        "n_training_samples = len(df_train)\n",
        "n_validation_samples = len(df_valid)\n",
        "\n",
        "print(\"Number of training samples:\", n_training_samples)\n",
        "print(\"Number of validation samples:\", n_validation_samples)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train[\"filepath\"], df_train[\"label\"]))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((df_valid[\"filepath\"], df_valid[\"label\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI7NGtkzd4pK"
      },
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [299, 299])\n",
        "\n",
        "\n",
        "def process_path(filepath, label):\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(filepath)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "valid_ds = valid_ds.map(process_path)\n",
        "train_ds = train_ds.map(process_path)\n",
        "# test_ds = test_ds\n",
        "for image, label in train_ds.take(1):\n",
        "    print(\"Image shape:\", image.shape)\n",
        "    print(\"Label:\", label.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGmeG0XaeBif"
      },
      "source": [
        "batch_size = 128\n",
        "optimizer = \"rmsprop\"\n",
        "\n",
        "def prepare_for_training(ds, cache=True, batch_size=64, shuffle_buffer_size=1000):\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "  # shuffle the dataset\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "  # split to batches\n",
        "  ds = ds.batch(batch_size)\n",
        "  \n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "valid_ds = prepare_for_training(valid_ds, batch_size=batch_size, cache=\"valid-cached-data\")\n",
        "train_ds = prepare_for_training(train_ds, batch_size=batch_size, cache=\"train-cached-data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw4UzOxnl9s4"
      },
      "source": [
        "batch = next(iter(valid_ds))\n",
        "\n",
        "def show_batch(batch):\n",
        "  plt.figure(figsize=(12,12))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(batch[0][n])\n",
        "      plt.title(class_names[batch[1][n].numpy()].title())\n",
        "      plt.axis('off')\n",
        "        \n",
        "show_batch(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQPjdcDPt0H9"
      },
      "source": [
        "module_url = \"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\"\n",
        "m = tf.keras.Sequential([\n",
        "    hub.KerasLayer(module_url, output_shape=[2048], trainable=False),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "m.build([None, 299, 299, 3])\n",
        "m.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "m.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KsmSclCnULa"
      },
      "source": [
        "model_name = f\"benign-vs-malignant_{batch_size}_{optimizer}\"\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "# saves model checkpoint whenever we reach better weights\n",
        "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(model_name + \"_{val_loss:.3f}.h5\", save_best_only=True, verbose=1)\n",
        "\n",
        "history = m.fit(train_ds, validation_data=valid_ds, \n",
        "                steps_per_epoch=n_training_samples // batch_size, \n",
        "                validation_steps=n_validation_samples // batch_size, verbose=1, epochs=1,\n",
        "                callbacks=[tensorboard, modelcheckpoint])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GET75UR0nXqs"
      },
      "source": [
        "test_metadata_filename = \"test.csv\"\n",
        "df_test = pd.read_csv(test_metadata_filename)\n",
        "n_testing_samples = len(df_test)\n",
        "print(\"Number of testing samples:\", n_testing_samples)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((df_test[\"filepath\"], df_test[\"label\"]))\n",
        "\n",
        "def prepare_for_testing(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  \n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  return ds\n",
        "\n",
        "\n",
        "test_ds = test_ds.map(process_path)\n",
        "test_ds = prepare_for_testing(test_ds, cache=\"test-cached-data\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9oeoghpnfWB"
      },
      "source": [
        "y_test = np.zeros((n_testing_samples,))\n",
        "X_test = np.zeros((n_testing_samples, 299, 299, 3))\n",
        "for i, (img, label) in enumerate(test_ds.take(n_testing_samples)):\n",
        "  # print(img.shape, label.shape)\n",
        "  X_test[i] = img\n",
        "  y_test[i] = label.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbGlg-h7qykF"
      },
      "source": [
        "print(\"y_test.shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHwlwp1Gq-kK"
      },
      "source": [
        "m.load_weights(\"benign-vs-malignant_128_rmsprop_0.420.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlz-sBiVrbR7"
      },
      "source": [
        "print(\"Evaluating the model...\")\n",
        "loss, accuracy = m.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", loss, \"  Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4to8SP0z9r9N"
      },
      "source": [
        "def get_predictions(threshold=None):\n",
        "\n",
        "  y_pred = m.predict(X_test)\n",
        "  if not threshold:\n",
        "    threshold = 0.5\n",
        "  result = np.zeros((n_testing_samples,))\n",
        "  for i in range(n_testing_samples):\n",
        "    # test melanoma probability\n",
        "    if y_pred[i][0] >= threshold:\n",
        "      result[i] = 1\n",
        "    # else, it's 0 (benign)\n",
        "  return result\n",
        "\n",
        "threshold = 0.23\n",
        "\n",
        "y_pred = get_predictions(threshold)\n",
        "accuracy_after = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy after setting the threshold:\", accuracy_after)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIUG8Af9-9kd"
      },
      "source": [
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "  cmn = confusion_matrix(y_test, y_pred)\n",
        "  # Normalise\n",
        "  cmn = cmn.astype('float') / cmn.sum(axis=1)[:, np.newaxis]\n",
        "  # print it\n",
        "  print(cmn)\n",
        "  fig, ax = plt.subplots(figsize=(10,10))\n",
        "  sns.heatmap(cmn, annot=True, fmt='.2f', \n",
        "              xticklabels=[f\"pred_{c}\" for c in class_names], \n",
        "              yticklabels=[f\"true_{c}\" for c in class_names],\n",
        "              cmap=\"Blues\"\n",
        "              )\n",
        "  plt.ylabel('Actual')\n",
        "  plt.xlabel('Predicted')\n",
        "  # plot the resulting confusion matrix\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_auc(y_true, y_pred):\n",
        "    \n",
        "    # prepare for figure\n",
        "    plt.figure()\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "    # obtain ROC AUC\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    # print score\n",
        "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "    # plot ROC curve\n",
        "    plt.plot(fpr, tpr, color=\"blue\", lw=2,\n",
        "                label='ROC curve (area = {f:.2f})'.format(d=1, f=roc_auc))\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC curves')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "plot_roc_auc(y_test, y_pred)\n",
        "sensitivity = sensitivity_score(y_test, y_pred)\n",
        "specificity = specificity_score(y_test, y_pred)\n",
        "\n",
        "print(\"Melanoma Sensitivity:\", sensitivity)\n",
        "print(\"Melanoma Specificity:\", specificity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgEiTm_a_SyB"
      },
      "source": [
        "def plot_images(X_test, y_pred, y_test):\n",
        "  predicted_class_names = np.array([class_names[int(round(id))] for id in y_pred])\n",
        "\n",
        "  plt.figure(figsize=(10,9))\n",
        "  for n in range(30, 60):\n",
        "      plt.subplot(6,5,n-30+1)\n",
        "      plt.subplots_adjust(hspace = 0.3)\n",
        "      plt.imshow(X_test[n])\n",
        "      # get the predicted label\n",
        "      predicted_label = predicted_class_names[n]\n",
        "      # get the actual true label\n",
        "      true_label = class_names[int(round(y_test[n]))]\n",
        "      if predicted_label == true_label:\n",
        "          color = \"blue\"\n",
        "          title = predicted_label.title()\n",
        "      else:\n",
        "          color = \"red\"\n",
        "          title = f\"{predicted_label.title()}, true:{true_label.title()}\"\n",
        "      plt.title(title, color=color)\n",
        "      plt.axis('off')\n",
        "  _ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")\n",
        "  plt.show()\n",
        "\n",
        "plot_images(X_test, y_pred, y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMqGfZegCsaE"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx0cT4b9CbZF"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kasvSsaJDIVn"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}